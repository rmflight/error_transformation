---
title: "Visualizing Effect of Data Transformations on Errors"
author: "Robert M Flight"
date: "`r Sys.time()`"
commit: "`r substr(git2r::branch_target(git2r::head(git2r::repository())), 1, 8)`"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(fakeDataWithError)
library(visualizationQualityControl)
library(cowplot)
library(dplyr)
library(errorTransformation)

poster_figure_loc <- "/home/rmflight/Documents/posters/dataTransformationsError/"
```

# Abstract

**Background**

In many omics analyses, a primary step in the data analysis is the application 
of a transformation to the data.  Transformations are generally employed to 
convert proportional error (variance) to additive error, which most statistical 
methods appropriately handle. However, omics data frequently contain error 
sources that result in both additive and proportional errors. To our knowledge, 
there has not been a systematic study on detecting the presence of proportional 
error in omics data, or the effect of transformations on the error structure. 

**Results**

In this work, we demonstrate a set of three simple graphs which facilitate the 
detection of proportional and mixed error in omics data when multiple replicates
are available. The three graphs illustrate proportional and mixed error in a 
visually compelling manner that is both straight-forward to recognize and to 
communicate. The graphs plot the 1) absolute difference in the range, 2)
standard deviation and 3) relative standard deviation against the mean signal
across replicates. In addition to showing the presence of different types of
error, these graphs readily demonstrate the effect of various transformations on
the error structure as well.

**Conclusions**

We have developed a straight-forward set of graphs that effectively summarize 
major types of error present in high replicate datasets. Using these graphical 
summaries we find that the logand hyperbolic inverse sin transforms are the most
effective method of the common methods employed for removing proportional error.

**Keywords**

error analysis, error visualization, omics error


# Introduction

Various scalings and transformations are often applied to -omics data to modify 
specific properties of the data, making the data more amenable to various
statistical procedures. One of the most common applications is to modify the
error structure, going from multiplicative error that is commonly present in any
data generated by counts at a detector (essentially all high-throughput -omics
data) to additive error, which most statistical methods expect.

Previous work has examined the influence of scalings and transformations on both
the structure of the data and the errors through the use of replicated nuclear 
magnetic resonance (NMR) [REF] and coupled gas chromatography mass spectrometry 
(GC-MS) experiments [REF]. Although insightful, these works did not provide
direct control over the exact type and amount of error present in the data. Most
of the discussion in previous work also concentrated on the shape of the spectra
after scaling and transformation. However, in many other -omics data types
outside of metabolomics where NMR and GC-MS are applied, there is no real
spectra, but simply an aggregation of values measured on independent features,
and therefore changes in shape of the overall spectra are largely irrelevant.

In the following, we demonstrate that the use of a simple summary of replicate 
experiments consisting of the **mean**, **maximum** - **minimum**, **standard 
deviation** (sd), and **relative standard deviation** (rsd) is useful as a 
visual indicator of the type and presence of errors in various -omics datasets.
A simple plot of both the **mean vs sd** and **mean vs rsd** is able to
determine whether the errors in an experiment are primarily **additive** 
(random, constant, baseline error), **proportional** (dependent on the signal 
value), or a **mixture**. From this visual summary, it is also possible to 
evaluate the impact of different scalings and transformations on the error 
structure in the data.

We evaluate the impact of the scalings and transformations through the use of 
synthetic data where specific amounts of **additive** and **proportional** error
have been added.

# Methods

All of the code necessary to regenerate this document can be found on Github at
https://github.com/rmflight/error_transformation.

## Data

```{r setup_data}
set.seed(1234)
n_point <- 1000
n_rep <- 100
offset <- 4
simulated_data <- c(rlnorm(n_point / 2, meanlog = 1, sdlog = 1),
                    runif(n_point / 2, 5, 100))
simulated_data <- simulated_data + offset
```

Simulated data was generated by drawing points from two different distributions:
1) a log-normal distribution with a mean in log-space of 1 and a standard
deviation of 1; and 2) a uniform distribution over the
range of 5 - 100, with `r n_point/2` points in each distribution. A value of 
`r offset` was added to the data purely to avoid having values less than 1 following the addition
of error, making visualization easier. These data points are the **pure**
initial data to which different types of error are added. From this set, 
`r n_rep` replicates are generated with either *additive* (`add`, 0.5), *proportional*
(`prop`, 0.1) or *mixed* (both additive and proportional, `mixed`) error (equations
1-3).

$$ x = \mu + \sigma_{add} $$

$$ x = \mu + \mu \cdot \rho_{prop} $$

$$ x = \mu + \sigma_{add} + \mu \cdot \rho_{prop} $$

### Additive Error

```{r add_error}
add_sd <- 0.5
add_error <- add_uniform_noise(n_rep, simulated_data, add_sd)
```

Additive error was added where the standard deviation was `r add_sd`. A plot
of two replicates is shown in Figure X.

### Proportional Error

```{r prop_error}
prop_sd <- 0.1
prop_error <- add_prop_noise(n_rep, simulated_data, prop_sd)
```

Proportional error was added with a relative standard deviation of `r prop_sd`. A
plot of two replicates is shown in Figure X.

### Mixed Error

```{r mix_error}
mix_error <- add_prop_uniform(n_rep, simulated_data, add_sd, prop_sd)
```

A mixture of additive and proportional errors was added using standard deviations
and relative standard deviations of `r add_sd` and `r prop_sd` respectively.


## Transformations

The transformations applied to the data include autoscaling, pareto scaling, 
log-transform (natural log), and power transform (using roots of 2 and 5).

# Results

Very often, high-throughput -omics replicates are visualized in a pairwise
manner, by plotting the replicates directly against each other, or rotating them
by 45 degrees as a Bland-Altman or MA plot (see Figure Xa and b). Overviews of
many replicate / samples can be provided by summarizing each pair by the
correlation or root mean squared error (RMSE), however neither of these provide
a way to view how or if errors are related to the value of a feature across all
replicates. The pairwise MA plot allows this for pairs, but examining a large
number of pairwise plots is tedious.

One simple extension is for each feature, to plot the difference between the
minimum and maximum value across replicates, vs the mean value, as shown in
Figure Xc. A more robust metric with essentially the same information is to plot the
standard deviation against the mean. This actually shows if there is
any relationship between the error (standard deviation) and the mean, which can
provide an indication of whether there is additive, or proportional errors
present. Adding a plot of the *relative standard deviation* (RSD, SD / mean) *vs the
mean* as well as *sd vs mean*  makes it possible to discern the presence of
additive, proportional, or mixed error ( see Figures X-Y for examples).

**Question: What is the best way to organize these plots? In the poster we could
easily divide the original and the error summary plots while keeping them on the
same line to make the link explicit with the other plots shown later, but we
don't really have that option in the paper. So, should the first two figures
be figure of original spaces (for all three error models), and then a figure
of the error summaries?**

```{r buildup_plots}
pair_frame <- data.frame(rep1 = add_error[,1], rep2 = add_error[,2])
add_pair_plot <- ggplot(pair_frame, aes(x = rep1, y = rep2)) + geom_point()

ma_frame <- data.frame(M = add_error[,1] - add_error[,2],
                      A = rowMeans(add_error[, 1:2]))
add_ma_plot <- ggplot(ma_frame, aes(x = A, y = M)) + geom_point()

diff_error <- apply(add_error, 1, function(x){
  max(x) - min(x)
})
range_frame <- data.frame(difference = diff_error,
                          mean = rowMeans(add_error))
add_diff_plot <- ggplot(range_frame, aes(x = mean, y = difference)) + geom_point()

add_error_summ <- summarize_data(t(add_error))
add_sd_plot <- filter(add_error_summ, type == "sd") %>% 
  ggplot(., aes(x = mean, y = var)) + geom_point() + ylab("sd") + geom_hline(yintercept = add_sd, color = "red")
add_rsd_plot <- filter(add_error_summ, type == "rsd") %>%
  ggplot(., aes(x = mean, y = var)) + geom_point() + ylab("rsd")

```


## No Transformation

### Additive Error

```{r add_plot}
ae_nt_diff <- plot_diff(add_nozero)
ae_nt_sd <- plot_sd(add_nozero)
ae_nt_sd <- ae_nt_sd + geom_hline(yintercept = add_sd, color = "red")

ae_nt_rsd <- plot_sd(add_nozero, sd_type = "rsd")
plot_grid(ae_nt_diff, ae_nt_sd, ae_nt_rsd, nrow = 1, labels = LETTERS[1:3])
```

### Proportional Error

```{r prop_plot}
pe_nt_diff <- plot_diff(prop_nozero)
pe_nt_sd <- plot_sd(prop_nozero)

pe_nt_rsd <- plot_sd(prop_nozero, sd_type = "rsd") + 
  geom_hline(yintercept = prop_sd, color = "red")

plot_grid(pe_nt_diff, pe_nt_sd, pe_nt_rsd, nrow = 1, labels = LETTERS[1:3])
```

### Mixed Error

```{r mix_plot}
me_nt_diff <- plot_diff(mix_nozero)
me_nt_sd <- plot_sd(mix_nozero) + geom_hline(yintercept = add_sd, color = "red")
me_nt_rsd <- plot_sd(mix_nozero, sd_type = "rsd") + 
  geom_hline(yintercept = prop_sd, color = "red")

plot_grid(me_nt_diff, me_nt_sd, me_nt_rsd, nrow = 1, labels = LETTERS[1:3])
```

## Auto-Scaling

### Additive

```{r auto_additive}
ae_as <- auto_scale(add_nozero)
ae_as_summary <- summarize_data(t(ae_as))
ae_as_diff <- plot_diff(ae_as, log_mean = log)
ae_as_sd <- plot_sd(ae_as, log_mean = log)
ae_as_rsd <- plot_sd(ae_as, sd_type = "rsd", log_mean = log)
plot_grid(ae_as_diff, ae_as_sd, ae_as_rsd, nrow = 1, labels = LETTERS[1:3])
```

### Proportional

```{r auto_proportional}
pe_as <- auto_scale(prop_nozero)
pe_as_diff <- plot_diff(pe_as, log_mean = log)
pe_as_sd <- plot_sd(pe_as, log_mean = log)
pe_as_rsd <- plot_sd(pe_as, sd_type = "rsd", log_mean = log)
plot_grid(pe_as_diff, pe_as_sd, pe_as_rsd, nrow = 1, labels = LETTERS[1:3])
```

### Mixed

```{r auto_mixed}
me_as <- auto_scale(mix_nozero)
me_as_diff <- plot_diff(me_as, log_mean = log)
me_as_sd <- plot_sd(me_as, log_mean = log)
me_as_rsd <- plot_sd(me_as, sd_type = "rsd", log_mean = log)
plot_grid(me_as_diff, me_as_sd, me_as_rsd, nrow = 1, labels = LETTERS[1:3])
```

```{r autoscale_check}
me_nt_summ <- summarize_data(t(mix_nozero))
max_me_nt <- filter(me_nt_summ, type == "rsd") %>% select(., var) %>% max()

me_as_summ <- summarize_data(t(me_as))
max_me_as <- filter(me_as_summ, type == "rsd") %>% select(., var) %>% max()
identical(max_me_nt, max_me_as)

auto_compare <- summarize_two(mix_nozero, me_as, sd_type = "rsd", name1 = "mix", name2 = "mix_auto")
auto_compare$mean <- log(auto_compare$mean)
ggplot(auto_compare, aes(x = var, fill = data)) + geom_density(alpha = 0.5)
ggplot(auto_compare, aes(x = mean, y = var, color = data)) + geom_point(alpha = 0.5)
```


Applying a variance or autoscaling to the data results in the removal of the 
additive error to a completely identical standard deviation of **1** across all
samples at all abundances (Figure X - Y). This applies across all of the
different error types. Although the standard deviation becomes identical and
constant, the maximum relative variance is the same, and the distribution of
the *rsd* values is identical.




## Pareto Scaling

### Additive

```{r pareto_add}
ae_ps <- pareto_scale(add_nozero)
ae_ps_diff <- plot_diff(ae_ps, log_mean = log)
ae_ps_sd <- plot_sd(ae_ps, log_mean = log)
ae_ps_rsd <- plot_sd(ae_ps, sd_type = "rsd", log_mean = log)
plot_grid(ae_ps_diff, ae_ps_sd, ae_ps_rsd, nrow = 1, labels = LETTERS[1:3])
```

### Proportional

```{r pareto_prop}
pe_ps <- pareto_scale(prop_nozero)
pe_ps_diff <- plot_diff(pe_ps, log_mean = log)
pe_ps_sd <- plot_sd(pe_ps, log_mean = log)
pe_ps_rsd <- plot_sd(pe_ps, sd_type = "rsd", log_mean = log)
plot_grid(pe_ps_diff, pe_ps_sd, pe_ps_rsd, nrow = 1, labels = LETTERS[1:3])
```

### Mixed

```{r pareto_mixed}
me_ps <- pareto_scale(mix_nozero)
me_ps_diff <- plot_diff(me_ps, log_mean = log)
me_ps_sd <- plot_sd(me_ps, log_mean = log)
me_ps_rsd <- plot_sd(me_ps, sd_type = "rsd", log_mean = log)
plot_grid(me_ps_diff, me_ps_sd, me_ps_rsd, nrow = 1, labels = LETTERS[1:3])
```

```{r pareto_check_rsd_ranges}
me_ps_summ <- summarize_data(t(me_ps))
max_me_ps <- filter(me_ps_summ, type == "rsd") %>% select(., var) %>% max()
identical(max_me_nt, max_me_ps)

pareto_compare <- summarize_two(mix_nozero, me_ps, sd_type = "rsd", name1 = "mix", name2 = "mix_pareto")

pareto_compare$mean <- log(pareto_compare$mean)
ggplot(pareto_compare, aes(x = var, fill = data)) + geom_density(alpha = 0.5)
ggplot(pareto_compare, aes(x = mean, y = var, color = data)) + geom_point(alpha = 0.5)
```

In contrast to autoscaling, pareto scaling modifies the values by the square
root of the variance. As shown in Figure X, this changes the absolute values of
the standard deviations, but does not change the distribution, or the dependence
of variance on the average abundance. In addition, the relative error remains
the same, as the maximum values of the rsd in the mixed error case for the
pareto scaled and non-transformed data are the same at `r max_me_nt`.


## Log Transformation

### Additive Error

```{r log_add_error}
log_add <- log(add_nozero)
ae_lt_diff <- plot_diff(log_add, log_mean = FALSE)
ae_lt_sd <- plot_sd(log_add, log_mean = FALSE)
ae_lt_rsd <- plot_sd(log_add, log_mean = FALSE, sd_type = "rsd")
plot_grid(ae_lt_diff, ae_lt_sd, ae_lt_rsd, nrow = 1, labels = LETTERS[1:3])
```

### Proportional Error

```{r log_prop_error}
log_prop <- log(prop_nozero)

pe_lt_diff <- plot_diff(log_prop, log_mean = FALSE)
pe_lt_sd <- plot_sd(log_prop, log_mean = FALSE)
pe_lt_rsd <- plot_sd(log_prop, log_mean = FALSE, sd_type = "rsd")
plot_grid(pe_lt_diff, pe_lt_sd, pe_lt_rsd, nrow = 1, labels = LETTERS[1:3])
```

### Mixed Error

```{r log_mix_error}
log_mix <- log(mix_nozero)

me_lt_diff <- plot_diff(log_mix, log_mean = FALSE)
me_lt_sd <- plot_sd(log_mix, log_mean = FALSE)
me_lt_rsd <- plot_sd(log_mix, log_mean = FALSE, sd_type = "rsd")
plot_grid(me_lt_diff, me_lt_sd, me_lt_rsd, nrow = 1, labels = LETTERS[1:3])
```

```{r check_log_transforms_add}
compare_lt_ae_sr <- rbind(
  summarize_data(t(add_nozero)) %>% filter(., type == "rsd") %>% mutate(., data = "add") %>% transform(., mean = log(mean)),
  summarize_data(t(log_add)) %>% filter(., type == "sd") %>% mutate(., data = "log"))

hist_compare_lt_ae_sr <- ggplot(compare_lt_ae_sr, aes(x = var, fill = data)) + geom_density(alpha = 0.5)
point_compare_lt_ae_sr <- ggplot(compare_lt_ae_sr, aes(x = mean, y = var, color = data)) + 
  geom_point(alpha = 0.5)

plot_grid(hist_compare_lt_ae_sr, point_compare_lt_ae_sr, nrow = 1, labels = LETTERS[1:2])

compare_lt_ae_rr <- rbind(
  summarize_data(t(add_nozero)) %>% filter(., type == "rsd") %>% mutate(., data = "add") %>% transform(., mean = log(mean)),
  summarize_data(t(log_add)) %>% filter(., type == "rsd") %>% mutate(., data = "log")
)
hist_compare_lt_ae_rr <- ggplot(compare_lt_ae_rr, aes(x = var, fill = data)) + 
  geom_density(alpha = 0.5)
point_compare_lt_ae_rr <- ggplot(compare_lt_ae_rr, aes(x = mean, y = var, color = data)) +
  geom_point(alpha = 0.5)
plot_grid(hist_compare_lt_ae_rr, point_compare_lt_ae_rr, nrow = 1, labels = LETTERS[1:2])
```

Log-transformations completely change the structure of the data. Figure X shows
that for the additive error only case, the SD vs mean looks more like the RSD vs
mean in the non-transformed case.

```{r check_lt_pe}
compare_lt_pe_rs <- rbind(
  summarize_data(t(prop_nozero)) %>% filter(., type == "rsd") %>% 
    mutate(., data = "prop") %>% transform(., mean = log(mean)),
  summarize_data(t(log_prop)) %>% filter(., type == "sd") %>%
    mutate(., data = "prop_log")
)

hist_comp_lt_pe_rs <- ggplot(compare_lt_pe_rs, aes(x = var, fill = data)) + 
  geom_density(alpha = 0.5)
point_comp_lt_pe_rs <- ggplot(compare_lt_pe_rs, aes(x = mean, y = var, color = data)) +
  geom_point(alpha = 0.5)

plot_grid(hist_comp_lt_pe_rs, point_comp_lt_pe_rs, nrow = 1, labels = LETTERS[1:2])

compare_lt_pe_rr <- rbind(
  summarize_data(t(prop_nozero)) %>% filter(., type == "rsd") %>% 
    mutate(., data = "prop") %>% transform(., mean = log(mean)),
  summarize_data(t(log_prop)) %>% filter(., type == "rsd") %>%
    mutate(., data = "prop_log")
)

hist_comp_lt_pe_rr <- ggplot(compare_lt_pe_rr, aes(x = var, fill = data)) + 
  geom_density(alpha = 0.5)
point_comp_lt_pe_rr <- ggplot(compare_lt_pe_rr, aes(x = mean, y = var, color = data)) +
  geom_point(alpha = 0.5)
plot_grid(hist_comp_lt_pe_rr, point_comp_lt_pe_rr, nrow = 1, labels = LETTERS[1:2])
```


For the proportional error case, the proportional error has been almost completely
transformed into additive error.

```{r check_lt_me}
compare_lt_me_rs <- rbind(
  summarize_data(t(mix_nozero)) %>% filter(., type == "rsd") %>%
    mutate(., data = "mix") %>% transform(., mean = log(mean)),
  summarize_data(t(log_mix)) %>% filter(., type == "sd") %>%
    mutate(., data = "mix_log")
)

hist_comp_lt_me_rs <- ggplot(compare_lt_me_rs, aes(x = var, fill = data)) + 
  geom_density(alpha = 0.5)
point_comp_lt_me_rs <- ggplot(compare_lt_me_rs, aes(x = mean, y = var, color = data)) +
  geom_point(alpha = 0.5)
plot_grid(hist_comp_lt_me_rs, point_comp_lt_me_rs, nrow = 1, labels = LETTERS[1:2])

compare_lt_me_rr <- rbind(
  summarize_data(t(mix_nozero)) %>% filter(., type == "rsd") %>%
    mutate(., data = "mix") %>% transform(., mean = log(mean)),
  summarize_data(t(log_mix)) %>% filter(., type == "rsd") %>%
    mutate(., data = "mix_log")
)

hist_comp_lt_me_rr <- ggplot(compare_lt_me_rr, aes(x = var, fill = data)) + 
  geom_density(alpha = 0.5)
point_comp_lt_me_rr <- ggplot(compare_lt_me_rr, aes(x = mean, y = var, color = data)) +
  geom_point(alpha = 0.5)
plot_grid(hist_comp_lt_me_rr, point_comp_lt_me_rr, nrow = 1, labels = LETTERS[1:2])

```


## Root Transform

A square root transform was applied to the data. The choice of using 2 as the
root is arbitrary, however depending on the size of the **tails** of the data
a higher root may be useful. 

```{r root_histogram}

```

### Additive Error

```{r root_add_plot}
root_add <- root_transform(add_nozero)
root_add2 <- root_transform(add_nozero, 5)

root_add_comb <- cbind(root_add, root_add2)
root_class <- rep(c("2", "5"), each = 100)
root_summary <- summarize_data(t(root_add_comb), root_class)

ae_rt_diff <- filter(root_summary, type == "diff") %>%
  ggplot(., aes(x = mean, y = var, color = class)) + geom_point()
ae_rt_sd <- filter(root_summary, type == "sd") %>%
  ggplot(., aes(x = mean, y = var, color = class)) + geom_point()
ae_rt_rsd <- filter(root_summary, type == "rsd") %>%
  ggplot(., aes(x = mean, y = var, color = class)) + geom_point()
plot_grid(ae_rt_diff, ae_rt_sd, ae_rt_rsd, nrow = 1, labels = LETTERS[1:3])
```

### Proportional Error

```{r root_prop_plot}
root_prop1 <- root_transform(prop_nozero)
root_prop2 <- root_transform(prop_nozero, root = 5)
root_prop_comb <- cbind(root_prop1, root_prop2)

root_pe_summary <- summarize_data(t(root_prop_comb), root_class)

root_pe_diff <- filter(root_pe_summary, type == "diff") %>%
  ggplot(., aes(x = mean, y = var, color = class)) + geom_point()
root_pe_sd <- filter(root_pe_summary, type == "sd") %>%
  ggplot(., aes(x = mean, y = var, color = class)) + geom_point()
root_pe_rsd <- filter(root_pe_summary, type == "rsd") %>%
  ggplot(., aes(x = mean, y = var, color = class)) + geom_point()

plot_grid(root_pe_diff, root_pe_sd, root_pe_rsd, nrow = 1, labels = LETTERS[1:3])
```

### Mixed Error

```{r root_mixed_plot}
root_mixed <- root_transform(mix_nozero)
root_mixed2 <- root_transform(mix_nozero, 5)

me_rt_comb <- cbind(root_mixed, root_mixed2)

me_rt_summary <- summarize_data(t(me_rt_comb), root_class)
me_rt_diff <- filter(me_rt_summary, type == "diff") %>%
  ggplot(., aes(x = mean, y = var, color = class)) + geom_point()
me_rt_sd <- filter(me_rt_summary, type == "sd") %>%
  ggplot(., aes(x = mean, y = var, color = class)) + geom_point()
me_rt_rsd <- filter(me_rt_summary, type == "rsd") %>%
  ggplot(., aes(x = mean, y = var, color = class)) + geom_point()

plot_grid(me_rt_diff, me_rt_sd, me_rt_rsd, nrow = 1, labels = LETTERS[1:3])
```



# Conclusion


# Session Information

```{r session_info}
ses_info <- devtools::session_info()
ses_info$platform
knitr::kable(ses_info$packages, format = "markdown")
```


# Create Markdown

```{r runit, eval=FALSE, echo = TRUE}
rmarkdown::render("vignettes/main_manuscript.Rmd", clean = FALSE,
                  output_dir = "outputs")
file.copy("vignettes/main_manuscript.utf8.md", "outputs/main_manuscript.utf8.md")
```
